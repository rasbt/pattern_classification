{
 "metadata": {
  "name": "",
  "signature": "sha256:dc3e161a36b8dff6911a99ef813605e20f11fd083b9fb6d09cc8da0b0f2f6cae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![logo](./Images/logo.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr>\n",
      "**Tutorials, examples, collections, and everything else that falls into the categories: pattern classification, machine learning, and data mining.**\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Table of Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [Introduction to Machine Learning and Pattern Classification](#Introduction-to-Machine-Learning-and-Pattern-Classification)\n",
      "* [Pre-Processing](#Pre-Processing)\n",
      "* [Model Evaluation](#Model-Evaluation)\n",
      "* [Parameter Estimation](#Parameter-Estimation)\n",
      "* [Statistical Pattern Classification Examples](#Statistical-Pattern-Classification-Examples)\n",
      "* [Resources](#Resources)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introduction to Machine Learning and Pattern Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Predictive modeling, supervised machine learning, and pattern classification - the big picture [[Markdown]](machine_learning/supervised_intro/introduction_to_supervised_machine_learning.md)\n",
      "* Entry Point: Data - Using Python's sci-packages to prepare data for Machine Learning tasks and other data analyses [[IPython nb]](machine_learning/scikit-learn/python_data_entry_point.ipynb)\n",
      "* An Introduction to simple linear supervised classification using `scikit-learn` [[IPython nb]](machine_learning/scikit-learn/scikit_linear_classification.ipynb)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Pre-Processing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Scaling and Normalization**\n",
      "    * About Feature Scaling: Standardization and Min-Max-Scaling (Normalization) [[IPython nb]](preprocessing/about_standardization_normalization.ipynb)\n",
      "* **Feature Selection**\n",
      "    * Sequential Feature Selection Algorithms [[IPython nb]](dimensionality_reduction/feature_selection/sequential_selection_algorithms.ipynb)\n",
      "* **Dimensionality Reduction**\n",
      "    * Principal Component Analysis (PCA) [[IPython nb]](dimensionality_reduction/projection/principal_component_analysis.ipynb)\n",
      "    * Linear Discriminant Analysis (LDA) [[IPython nb]](dimensionality_reduction/projection/linear_discriminant_analysis.ipynb)\n",
      "    * The effect of scaling and mean centering of variables prior to a PCA [[PDF]](./dimensionality_reduction/projection/scale_center_pca/scale_center_pca.pdf)    \n",
      "    * Kernel tricks and nonlinear dimensionality reduction via PCA [[IPython nb]](dimensionality_reduction/projection/kernel_pca.ipynb)\n",
      "    "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model Evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Cross-Validation**\n",
      "    * Streamline your cross-validation workflow - scikit-learn's Pipeline in action [[IPython nb]](machine_learning/scikit-learn/scikit-pipeline.ipynb)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Parameter Estimation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Parametric Techniques**\n",
      "    * Introduction to the Maximum Likelihood Estimate (MLE) [[IPython nb]](parameter_estimation_techniques/maximum_likelihood_estimate.ipynb)\n",
      "    * How to calculate Maximum Likelihood Estimates (MLE) for different distributions [[IPython nb]](parameter_estimation_techniques/max_likelihood_est_distributions.ipynb)\n",
      "\n",
      "* **Non-Parametric Techniques**\n",
      "    * Kernel density estimation via the Parzen-window technique [[IPython nb]](parameter_estimation_techniques/parzen_window_technique.ipynb)\n",
      "    * The K-Nearest Neighbor (KNN) technique\n",
      "\n",
      "* **Regression Analysis**\n",
      "    * Linear Regression\n",
      "        * Least-Squares fit [[IPython nb]](data_fitting/regression/linregr_least_squares_fit.ipynb)\n",
      "    * Non-Linear Regression"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Statistical Pattern Classification Examples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Supervised Learning**\n",
      "    * Parametric Techniques\n",
      "        * Univariate Normal Density\n",
      "            * Ex1: 2-classes, equal variances, equal priors [[IPython nb]](stat_pattern_class/supervised/parametric/1_stat_superv_parametric.ipynb)\n",
      "            * Ex2: 2-classes, different variances, equal priors [[IPython nb]](stat_pattern_class/supervised/parametric/2_stat_superv_parametric.ipynb)\n",
      "            * Ex3: 2-classes, equal variances, different priors [[IPython nb]](stat_pattern_class/supervised/parametric/3_stat_superv_parametric.ipynb)\n",
      "            * Ex4: 2-classes, different variances, different priors, loss function [[IPython nb]](stat_pattern_class/supervised/parametric/4_stat_superv_parametric.ipynb)\n",
      "            * Ex5: 2-classes, different variances, equal priors, loss function, cauchy distr.[[IPython nb]](stat_pattern_class/supervised/parametric/5_stat_superv_parametric.ipynb)\n",
      "\n",
      "        * Multivariate Normal Density\n",
      "            * Ex5: 2-classes, different variances, equal priors, loss function [[IPython nb]](stat_pattern_class/supervised/parametric/5_stat_superv_parametric.ipynb)\n",
      "            * Ex7: 2-classes, equal variances, equal priors [[IPython nb]](stat_pattern_class/supervised/parametric/7_stat_superv_parametric.ipynb)\n",
      "\n",
      "    * Non-Parametric Techniques"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Resources"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Matplotlib examples - Visualization techniques for exploratory data analysis [[IPython nb]](resources/matplotlib_viz_gallery.ipynb)\n",
      "\n",
      "* Copy-and-paste ready LaTex equations [[Markdown]](resources/latex_equations.md)\n",
      "\n",
      "* Open-source datasets [[Markdown]](resources/dataset_collections.md)\n",
      "\n",
      "* Free Machine Learning eBooks [[Markdown]](resources/machine_learning_ebooks.md)\n",
      "\n",
      "* Terms in data science defined in less than 50 words [[Markdown]](resources/data_glossary.md)\n",
      "\n",
      "* Useful libraries for data science in Python [[Markdown]](resources/python_data_libraries.md)\n",
      "\n",
      "* General Tips and Advices [[Markdown]](resources/general_tips_and_advices.md)\n",
      "\n",
      "* A matrix cheatsheat for Python, R, Julia, and MATLAB [[HTML]](http://sebastianraschka.com/github/pattern_classification/matrix_cheatsheet_table.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}